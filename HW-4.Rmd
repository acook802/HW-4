---
title: "MATH 216 Homework 4"
author: "WRITE YOUR NAME HERE"
output: html_document
---

```{r, echo=FALSE, message=FALSE, warning=FALSE}
# For data manipulation and visualization
suppressPackageStartupMessages(library(dplyr))
suppressPackageStartupMessages(library(ggplot2))
suppressPackageStartupMessages(library(tidyr))
suppressPackageStartupMessages(library(knitr))
# For US county and state maps
suppressPackageStartupMessages(library(maps))
# For loading in shapefiles
suppressPackageStartupMessages(library(rgdal))
suppressPackageStartupMessages(library(maptools))
# For interactive maps
suppressPackageStartupMessages(library(leaflet))
```

## Admistrative:

Please indicate

* Who you collaborated with: Jacob Dixon, Carter Merenstein
* Roughly how much time you spent on this HW: Close to 9 hours
* What gave you the most trouble: leaflet!! and tiny things like states with two names not populating or organizing data to be in the correct format. It is frustrating to know conceptually what to do and to feel like there are so many small roadblocks.
* Any comments you have:I think this is a cool, relevant data set! I just wish it wasn't taking me so long on such nice and also hectic days... 





## Question 1:

```{r, cache=TRUE, echo=FALSE}
# Load state and county map of US in 2010 from the maps package and convert them
# to data frames so that we can ggplot them.
US_state <- map_data("state") %>% 
  tbl_df()
US_county <- map_data("county") %>% 
  tbl_df()
```

### Choropleth Map of US Voter Behavior in 2000

Download the results of the 2000 election from the [School of Public Affairs at 
American University in DC](http://www.american.edu/spa/ccps/Data-Sets.cfm) and 
create a map involving only the lower 48 states that show voter behavior at a 
**county** level. To keep things simple let's only consider George W. Bush, Al
Gore, and Ralph Nader. Your write-up must include:

1. A [choropleth map](https://en.wikipedia.org/wiki/Choropleth_map) where
    * Counties are filled with red when they tend to favor Bush
    * Counties are filled with white when they tend to be split
    * Counties are filled with blue when they tend to favor Gore and Nader
2. An answer to the following question: which states exhibit the greatest
**within state heterogeneity** in voting? Come up with a mathematical
justification.


### Hints

* Consider `scale_fill_gradient2(name="", low="blue", high="red", mid="white")` 
for the appropriate "mid" point.  See the ggplot2 webpage for [this
command](http://docs.ggplot2.org/0.9.3.1/scale_gradient2.html) for inspiration.
* I believe the county map is from 2010, whereas the election data is from 2000,
as such certain counties will not match up. The number is not that large.
* [Counties in
Virginia](http://en.wikipedia.org/wiki/List_of_counties_in_Virginia)


### Code Hints

This function eliminates all non-alphanumeric characters and spaces and converts
all text to lower case:

```{r}
clean_text <- function(text){
  text <- gsub("[^[:alnum:]]", "", text)
  text <- gsub(" ", "", text)
  text <- tolower(text)
  return(text)
}
clean_text("HeLLO wOrLd.")
```

For the following `ggplot`, see how I didn't define `data` nor any `aes`thetics
in the base `ggplot`, but only within the respective `geom`'s. This is a nice
trick that allows you to have different `data` and different `aes` apply to
different `geom`'s; in this case state-level vs county-level data.

```{r}
ggplot(data=NULL) +
  geom_polygon(data=US_county, aes(x=long, y=lat, group=group, fill=1)) +
  geom_path(data=US_county, aes(x=long, y=lat, group=group), col="black", size=0.05) +
  geom_path(data=US_state, aes(x=long, y=lat, group=group), col="black", size=0.1) +
  coord_map()
```


### Write-Up

```{r, fig.width=12, fig.height=6}

election_county <- read.csv("/Users/Ali/Math_216/HW-4/CY/COUNTY.csv", header = T) %>% 
  tbl_df()


#Q1

clean_text <- function(text){
  text <- gsub("[^[:alnum:]]", "", text)
  text <- gsub(" ", "", text)
  text <- tolower(text)
  return(text)
}



#format state and county to match US_county style
election_county$STATE <- clean_text(election_county$STATE)
election_county$COUNTY <- clean_text(election_county$COUNTY)

#need states with two words in their name to all be alike
US_county$region <- clean_text(US_county$region)
US_county$subregion <- clean_text(US_county$subregion)

#join to add election data to county location
county_data <- left_join(US_county, election_county, by = c("region" = "STATE", "subregion" = "COUNTY" ) )

# re cast election data as numeric, not factor
county_data$PBUSH <- as.numeric(as.character(county_data$PBUSH))
county_data$PGORE <- as.numeric(as.character(county_data$PGORE))
county_data$PNADER <- as.numeric(as.character(county_data$PNADER))

party <- ifelse(county_data$PBUSH >= 0.5, 1, 
                ifelse(county_data$PGORE + county_data$PNADER >= 0.5, -1, 0))

county_data <- mutate(county_data, party)

ggplot(data=NULL) +
  geom_polygon(data=county_data, aes(x=long, y=lat, group=group, fill=party)) +
  geom_path(data=county_data, aes(x=long, y=lat, group=group), col="black", size=0.05) +
  geom_path(data=US_state, aes(x=long, y=lat, group=group), col="black", size=0.1) +
  coord_map() +
  scale_fill_gradient2(name="", low="blue", high="red", mid="white")

#where are the missing counties coming from?
# make this a plotly graph

#proportion of difference in counties per state 
#add up and divide by numer of counties per state. closer to 0 means more split. more -/+ means less split
#rank states 

num_counties <- US_county %>% distinct(subregion) %>% 
  group_by(region) %>% tally() %>% rename(count = n)

election_score_state <- aggregate(county_data$party, by=list(region=county_data$region), FUN=sum, na.rm = TRUE)
election_score_state <- election_score_state %>% mutate(prop = x/num_counties$count) 
election_score_state$prop <- abs(election_score_state$prop)
election_score_state <- election_score_state %>% arrange(prop)

#this gives you an idea of county to county heterogenaity (i.e. was there a lot of discrepancy
#location to location in the state) but gives you no idea about population
#multiply by pop to weight each county divide by population of state?
```






## Question 2:

In this question, you must make an interactive "Single File" Shiny app that uses
Leaflet. For all 184 census tracts in VT in the 2010 census, present
information on the proportion of the population that is either

* White
* African-American
* Hispanic
* Asian and Pacific Island
* Other, including those of two or more races

Use [Social Explorer](http://www.socialexplorer.com/) to get census data. I did
a demo of this in class. If you don't remember how or are stuck, please speak to
me or get help from your peers. Do not submit copies of the same file.

There should be some mechanism in your Shiny app that allows one the user to toggle
between the different ethnic groups.


### Loading Shapefile Data

Here is some starter code:

```{r}
#Q2

shapefile_name <- paste(getwd(), "/VT_census_tracts/tl_2015_50_tract.shp", sep="")
VT <- readOGR(shapefile_name, layer = "tl_2015_50_tract", verbose = FALSE)
leaflet(VT) %>%
  addTiles() %>% 
  addPolylines(color="black", weight=1)

VT_race <- read.csv("/Users/Ali/Math_216/HW-4/VT_race_data.csv")

#rename columns
VT_race <- dplyr::rename(VT_race, White = `SE_T054_002`, African_American = `SE_T054_003`, Hispanic = `SE_T055_010`, 
                         Asian = `SE_T054_005`, Pacific_Islander = `SE_T054_006`, Two_plus = `SE_T054_008`, Other = `SE_T054_007`, total_pop = `SE_T054_001`)

VT_race <- VT_race %>% select(Geo_NAME, Geo_QName, Geo_FIPS, total_pop, White, African_American, Hispanic, Asian, Pacific_Islander, Other, Two_plus)

#find proportions
VT_race$prop_white <- VT_race$White/VT_race$total_pop
VT_race$prop_African_American <- VT_race$African_American/VT_race$total_pop
VT_race$prop_Hispanic <- VT_race$Hispanic/VT_race$total_pop
VT_race$prop_Asian_pacific <- (VT_race$Asian + VT_race$Pacific_Islander)/VT_race$total_pop
VT_race$prop_Other <- (VT_race$Other + VT_race$Two_plus)/VT_race$total_pop

# The following bit of code
# -Assigns a unique id to each census tract
# -fortify() and inner_join() to create a ggplot'able data frame. You don't need
#  to understand these functions.
VT$id <- rownames(VT@data)
VT_points <- fortify(VT, region="id")
VT_df <- inner_join(VT_points, VT@data, by="id")

#join race data with VT data
VT_df$GEOID <- as.numeric(as.character(VT_df$GEOID))
VT_census <- left_join(VT_df, VT_race, by = c("GEOID" = "Geo_FIPS"))


# color palatte

binpal <- colorBin("Blues", VT_census$prop_white)

#prop_white
leaflet(VT) %>%
  addTiles() %>% 
  addPolylines(color="black", weight=1) %>% 
  addPolygons(stroke = FALSE, fillOpacity = 0.5, smoothFactor = 0.5,
              color = ~binpal(VT_census$prop_white))

#prop_hispanic 
leaflet(VT) %>%
  addTiles() %>% 
  addPolylines(color="black", weight=1) %>% 
  addPolygons(stroke = FALSE, fillOpacity = 0.5, smoothFactor = 0.5,
              color = ~binpal(VT_census$prop_Hispanic))

#prop_african american 
leaflet(VT) %>%
  addTiles() %>% 
  addPolylines(color="black", weight=1) %>% 
  addPolygons(stroke = FALSE, fillOpacity = 0.5, smoothFactor = 0.5,
              color = ~binpal(VT_census$prop_African_American))

#chlorpleth
#click on box and leaflet superimposes
# fill based on each individual
# fill by race 
```


### Write-Up

Upload your shiny app to the Middlebury Shiny Server (see Lecture 16) and post
the url to the app [here](https://www.nhl.com/), replacing the nhl.com link with 
the link to your app.

Comment on general ethnic demographic trends that's more substantive than just
"Vermont is really white."



